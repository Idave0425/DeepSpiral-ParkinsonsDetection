{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Idave0425/DeepSpiral-ParkinsonsDetection/blob/main/ID_MobileNetV2_Test_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b76652cf",
        "outputId": "807048dc-9368-44ed-ff71-64f6a3f8441c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "id": "b76652cf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78ae10bb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Please replace the brackets below with the drive location of your folders which included subfolders for images\n",
        "# Sample path: /content/drive/My Drive/ImageClassification\n",
        "TRAINING_PATH = '/content/drive/Shareddrives/1:1_Ishan_Dave/Train'\n",
        "TEST_PATH = '/content/drive/Shareddrives/1:1_Ishan_Dave/Test'"
      ],
      "id": "78ae10bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bcb8666"
      },
      "outputs": [],
      "source": [
        "def create_model(base_model, num_classes):\n",
        "    import tensorflow as tf\n",
        "    # Grab the last layer and add a few extra layers to it\n",
        "    x=base_model.output\n",
        "    x=GlobalAveragePooling2D()(x)\n",
        "    # Dense layer 1\n",
        "    x=tf.keras.layers.Dense(100,activation='relu', kernel_initializer=tf.keras.initializers.VarianceScaling(), use_bias=True)(x)\n",
        "\n",
        "    # Final layer with softmax activation\n",
        "    preds=tf.keras.layers.Dense(num_classes,activation='softmax', kernel_initializer=tf.keras.initializers.VarianceScaling(), use_bias=False)(x)\n",
        "\n",
        "    # Create the final model\n",
        "    model=Model(inputs=base_model.input,outputs=preds)\n",
        "    return model\n"
      ],
      "id": "0bcb8666"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7733499"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(optimizer_name, learning_rate):\n",
        "    # Import keras optimizers\n",
        "    from tensorflow.keras.optimizers import Adam, Adadelta, Adagrad, Adamax, Ftrl, Nadam, RMSprop, SGD\n",
        "    print('Selected Optimizer', optimizer_name)\n",
        "    switcher = {\n",
        "        'Adadelta': Adadelta(learning_rate=learning_rate),\n",
        "        'Adagrad': Adagrad(learning_rate=learning_rate),\n",
        "        'Adam': Adam(learning_rate=learning_rate),\n",
        "        'Adamax': Adamax(learning_rate=learning_rate),\n",
        "        'FTRL': Ftrl(learning_rate=learning_rate),\n",
        "        'NAdam': Nadam(learning_rate=learning_rate),\n",
        "        'RMSprop': RMSprop(learning_rate=learning_rate),\n",
        "        'Gradient Descent': SGD(learning_rate=learning_rate)\n",
        "    }\n",
        "    # If optimizer_name is empty, Adam will be return as default optimizer\n",
        "    return switcher.get(optimizer_name, Adam(learning_rate=learning_rate))\n"
      ],
      "id": "a7733499"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1978032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd79b86f-a520-4f80-b633-a0a4eed84e4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 43 images belonging to 2 classes.\n",
            "Found 13 images belonging to 2 classes.\n",
            "dict_keys(['Healthy', 'Parkinsons'])\n",
            "154\n",
            "Selected Optimizer Adam\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 5s 1s/step - loss: 0.8180 - accuracy: 0.4186 - val_loss: 1.2798 - val_accuracy: 0.8462\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 1s 494ms/step - loss: 1.6918 - accuracy: 0.7907 - val_loss: 0.6529 - val_accuracy: 0.8462\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 1s 481ms/step - loss: 0.7760 - accuracy: 0.7907 - val_loss: 0.3433 - val_accuracy: 0.8462\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 1s 912ms/step - loss: 0.4575 - accuracy: 0.7907 - val_loss: 0.5564 - val_accuracy: 0.8462\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 1s 878ms/step - loss: 0.5389 - accuracy: 0.8372 - val_loss: 0.5344 - val_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 1s 474ms/step - loss: 0.5007 - accuracy: 0.8837 - val_loss: 0.4056 - val_accuracy: 0.8462\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 1s 892ms/step - loss: 0.4160 - accuracy: 0.7907 - val_loss: 0.3311 - val_accuracy: 0.8462\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.4253 - accuracy: 0.7907 - val_loss: 0.3258 - val_accuracy: 0.8462\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 1s 479ms/step - loss: 0.4335 - accuracy: 0.7907 - val_loss: 0.3141 - val_accuracy: 0.8462\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 1s 876ms/step - loss: 0.4131 - accuracy: 0.7907 - val_loss: 0.2822 - val_accuracy: 0.8462\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 1s 877ms/step - loss: 0.3630 - accuracy: 0.7907 - val_loss: 0.2646 - val_accuracy: 0.8462\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 1s 927ms/step - loss: 0.3414 - accuracy: 0.7907 - val_loss: 0.2524 - val_accuracy: 0.8462\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 1s 877ms/step - loss: 0.3335 - accuracy: 0.7907 - val_loss: 0.2399 - val_accuracy: 0.8462\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 1s 482ms/step - loss: 0.3257 - accuracy: 0.8140 - val_loss: 0.2237 - val_accuracy: 0.8462\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 1s 492ms/step - loss: 0.3169 - accuracy: 0.7907 - val_loss: 0.2106 - val_accuracy: 0.8462\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 1s 506ms/step - loss: 0.3140 - accuracy: 0.7907 - val_loss: 0.2021 - val_accuracy: 0.8462\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 1s 929ms/step - loss: 0.3098 - accuracy: 0.7907 - val_loss: 0.1943 - val_accuracy: 0.8462\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3068 - accuracy: 0.7907 - val_loss: 0.1904 - val_accuracy: 0.8462\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 1s 468ms/step - loss: 0.2970 - accuracy: 0.8605 - val_loss: 0.1857 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 1s 889ms/step - loss: 0.2865 - accuracy: 0.8837 - val_loss: 0.1672 - val_accuracy: 0.9231\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 1s 477ms/step - loss: 0.2734 - accuracy: 0.8837 - val_loss: 0.1560 - val_accuracy: 0.8462\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 1s 478ms/step - loss: 0.2656 - accuracy: 0.8140 - val_loss: 0.1639 - val_accuracy: 0.8462\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 1s 894ms/step - loss: 0.2745 - accuracy: 0.8140 - val_loss: 0.1498 - val_accuracy: 0.8462\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 1s 491ms/step - loss: 0.2578 - accuracy: 0.8605 - val_loss: 0.1463 - val_accuracy: 0.8462\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 1s 902ms/step - loss: 0.2684 - accuracy: 0.9070 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 1s 876ms/step - loss: 0.2849 - accuracy: 0.9302 - val_loss: 0.1747 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 0.2789 - accuracy: 0.9302 - val_loss: 0.1467 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2529 - accuracy: 0.8837 - val_loss: 0.1373 - val_accuracy: 0.8462\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 1s 518ms/step - loss: 0.2551 - accuracy: 0.7907 - val_loss: 0.1515 - val_accuracy: 0.8462\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 1s 495ms/step - loss: 0.2643 - accuracy: 0.8140 - val_loss: 0.1245 - val_accuracy: 0.9231\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 1s 876ms/step - loss: 0.2265 - accuracy: 0.8837 - val_loss: 0.1302 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 1s 888ms/step - loss: 0.2192 - accuracy: 0.9302 - val_loss: 0.1374 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 1s 909ms/step - loss: 0.2256 - accuracy: 0.9302 - val_loss: 0.1356 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 1s 476ms/step - loss: 0.2153 - accuracy: 0.9302 - val_loss: 0.1241 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 1s 885ms/step - loss: 0.2046 - accuracy: 0.8837 - val_loss: 0.1215 - val_accuracy: 0.9231\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 1s 497ms/step - loss: 0.2073 - accuracy: 0.8837 - val_loss: 0.1209 - val_accuracy: 0.8462\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 1s 870ms/step - loss: 0.2020 - accuracy: 0.8605 - val_loss: 0.1182 - val_accuracy: 0.9231\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 1s 882ms/step - loss: 0.1940 - accuracy: 0.8837 - val_loss: 0.1174 - val_accuracy: 0.8462\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 1s 905ms/step - loss: 0.1906 - accuracy: 0.8837 - val_loss: 0.1191 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 1s 494ms/step - loss: 0.1890 - accuracy: 0.8837 - val_loss: 0.1187 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 1s 505ms/step - loss: 0.1855 - accuracy: 0.9070 - val_loss: 0.1160 - val_accuracy: 0.9231\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 1s 472ms/step - loss: 0.1837 - accuracy: 0.8837 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 1s 470ms/step - loss: 0.1774 - accuracy: 0.8837 - val_loss: 0.1150 - val_accuracy: 0.9231\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 1s 476ms/step - loss: 0.1767 - accuracy: 0.8837 - val_loss: 0.1183 - val_accuracy: 0.8462\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 1s 903ms/step - loss: 0.1819 - accuracy: 0.8372 - val_loss: 0.1149 - val_accuracy: 0.9231\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 1s 993ms/step - loss: 0.1727 - accuracy: 0.8837 - val_loss: 0.1123 - val_accuracy: 0.9231\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 2s 921ms/step - loss: 0.1691 - accuracy: 0.9070 - val_loss: 0.1131 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 1s 855ms/step - loss: 0.1707 - accuracy: 0.8837 - val_loss: 0.1131 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 1s 898ms/step - loss: 0.1706 - accuracy: 0.8837 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 1s 901ms/step - loss: 0.1689 - accuracy: 0.9302 - val_loss: 0.1134 - val_accuracy: 0.9231\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import packages needed to create a image classification model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow import keras\n",
        "\n",
        "# Initialize hyper params\n",
        "epochs = 50 #<-- increase for higher accuracy\n",
        "base_learning_rate = 0.005 #decrease for different results; use excel sheet to note down results from each change to learning rate and epochs\n",
        "optimizer = 'Adam'\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# Create the data generation pipeline for training and validation\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_PATH,\n",
        "                                                target_size=IMG_SIZE,\n",
        "                                                color_mode='rgb',\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True,\n",
        "                                                )\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_PATH,\n",
        "                                                target_size=IMG_SIZE,\n",
        "                                                color_mode='rgb',\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True,\n",
        "                                                )\n",
        "\n",
        "print(validation_generator.class_indices.keys())\n",
        "# Download the model, valid alpha values [0.25,0.35,0.5,0.75,1]\n",
        "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet', alpha=0.35)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "# Specify the number of classes\n",
        "num_classes = 2\n",
        "\n",
        "# Create the base model\n",
        "model = create_model(base_model,num_classes)\n",
        "\n",
        "print(len(base_model.layers))\n",
        "\n",
        "model.compile(optimizer = get_optimizer(optimizer_name=optimizer,learning_rate=base_learning_rate),loss='CategoricalCrossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "early_stopping_monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,\n",
        "    patience=30,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "step_size_train = train_generator.n//train_generator.batch_size\n",
        "history_fine = model.fit(train_generator,\n",
        "                        epochs=epochs,\n",
        "                        validation_data = validation_generator,\n",
        "                        verbose=1)"
      ],
      "id": "e1978032"
    },
    {
      "cell_type": "code",
      "source": [
        "def visualization():\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(history_fine.history)\n",
        "    #loss plots\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.plot(df['loss'], color='red', label = \"Training_loss\")\n",
        "    plt.plot(df['val_loss'], color='blue')\n",
        "    plt.legend(['Training Loss','Validation loss'],loc = 'best' )\n",
        "    plt.title('Line plot of Training and Validation loss')\n",
        "    plt.ylim(0,1)\n",
        "    plt.show()\n",
        "\n",
        "    #accuracy plots\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.plot(df['accuracy'], color='red')\n",
        "    plt.plot(df['val_accuracy'], color='blue')\n",
        "    plt.legend(['Training acc','Validation acc'],loc = 'best' )\n",
        "    plt.title('Line plot of Training and Validation Accuracies')\n",
        "    plt.ylim(0,1)\n",
        "    plt.show()\n",
        "\n",
        "visualization()"
      ],
      "metadata": {
        "id": "VIV_LOPybQWa"
      },
      "id": "VIV_LOPybQWa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8756be45"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import numpy for calculating best model accuracy\n",
        "import numpy as np\n",
        "# Populating matrics -> accuracy & loss\n",
        "acc = history_fine.history['accuracy']\n",
        "val_acc = history_fine.history['val_accuracy']\n",
        "\n",
        "loss = history_fine.history['loss']\n",
        "val_loss = history_fine.history['val_loss']\n",
        "\n",
        "print('Training Accuracy: ', acc)\n",
        "print('Validation Accuracy: ', val_acc)\n",
        "print('Training Loss: ', loss)\n",
        "print('Validation Loss: ', val_loss)\n",
        "best_model_accuracy = history_fine.history['val_accuracy'][np.argmin(history_fine.history['val_loss'])]\n",
        "print('best model accuracy: ', best_model_accuracy)\n"
      ],
      "id": "8756be45"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c863fdc"
      },
      "outputs": [],
      "source": [
        "def seperate_labels(generator):\n",
        "    x_validation = []\n",
        "    y_validation = []\n",
        "    num_seen = 0\n",
        "\n",
        "    for x, labels in generator:\n",
        "        x_validation.append(x)\n",
        "        y_validation.append([argmax(label) for label in labels])\n",
        "        num_seen += len(x)\n",
        "        if num_seen == generator.n: break\n",
        "\n",
        "    x_validation = np.concatenate(x_validation)\n",
        "    y_validation = np.concatenate(y_validation)\n",
        "    return x_validation, y_validation\n"
      ],
      "id": "4c863fdc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a650757c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate and display the confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.core.fromnumeric import argmax\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "x_validation, y_validation = seperate_labels(validation_generator)\n",
        "y_pred = model.predict(x_validation, batch_size=BATCH_SIZE)\n",
        "predictions = np.apply_along_axis(argmax, 1, y_pred)\n",
        "display_labels = validation_generator.class_indices.keys()\n",
        "\n",
        "# ConfusionMatrixDisplay.from_predictions(y_validation, predictions, display_labels=display_labels, cmap=\"binary\")\n",
        "# plt.show()\n"
      ],
      "id": "a650757c"
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(confusion_matrix(y_validation, predictions), annot = True, fmt = 'g', cmap = \"Blues\",xticklabels=display_labels, yticklabels=display_labels)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0hlIInn6bhOE"
      },
      "id": "0hlIInn6bhOE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_validation, predictions))"
      ],
      "metadata": {
        "id": "ek591f4PcMvK"
      },
      "id": "ek591f4PcMvK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f13b9f0c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Predicting code for an image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "# Please replace the brackets below with the location of your image which need to predict\n",
        "img_path = '<>'\n",
        "img = image.load_img(img_path, target_size=IMG_SIZE)\n",
        "img_array = image.img_to_array(img)\n",
        "img_batch = np.expand_dims(img_array, axis=0)\n",
        "img_preprocessed = preprocess_input(img_batch)\n",
        "prediction = model.predict(img_preprocessed)\n",
        "print(prediction)\n"
      ],
      "id": "f13b9f0c"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}