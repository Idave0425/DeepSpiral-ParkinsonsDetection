Overview
This repository contains the code and trained models for the research project “Automated Detection of Parkinson’s Disease Patterns in Spiral Drawings Using Convolutional Neural Networks” by Ishan Dave (University of California, Berkeley). The project investigates how lightweight deep-learning models—specifically MobileNetV2 and ResNet50—can detect Parkinson’s disease (PD) from spiral drawings generated by patients and healthy subjects. This approach offers a non-invasive, cost-effective, and accessible alternative to traditional diagnostic techniques such as MRI, PET, and DaT scans.

Motivation
Parkinson’s disease affects over 10 million people worldwide, leading to significant motor impairments and a yearly U.S. healthcare cost of approximately $52 billion.
Traditional diagnostics are expensive, invasive, and often detect the disease only after major neurodegeneration has occurred. This project aims to bridge that gap by using AI-based pattern recognition on handwriting data—specifically spiral drawings—to identify early-stage PD indicators.

Dataset
The dataset used is the Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson’s Disease, collected by Isenkul et al. (2014) and hosted on the UCI Machine Learning Repository.

Format: CSV files containing X, Y, Z coordinates, pressure, grip angle, and timestamps
Processing: The coordinate data was rendered into 2D spiral images used as input for CNN models
Split: 70% training, 14% testing, and 16% validation

Methodology
Two pre-trained Convolutional Neural Network (CNN) architectures were compared in this study: MobileNetV2 and ResNet50. MobileNetV2 is a lightweight, efficient model optimized for real-time or mobile use, while ResNet50 is a deeper, high-capacity model used as a baseline for comparison.

Modifications applied to both models included adding a dense layer of 100 neurons with ReLU activation and a softmax output layer for binary classification (Healthy vs. Parkinson’s).

The training configuration consisted of learning rates ranging from 0.00001 to 0.005, epochs between 10 and 50, using the Adam optimizer and categorical cross-entropy as the loss function. The evaluation metrics used were accuracy, precision, recall, and F1-score.

Results
MobileNetV2 achieved a test accuracy of 91 percent with a weighted average precision of 0.92 and a recall of 0.91. ResNet50 achieved a lower accuracy of 82 percent, with a precision of 0.67 and a recall of 0.82. These results show that MobileNetV2 outperformed the deeper ResNet50 model both in accuracy and efficiency. This demonstrates that lightweight convolutional networks can be highly effective for medical diagnostic applications where computational resources are limited.

The repository contains the following main files:

Best_Model_Training_and_Saving – final training and model-saving script
Create_Test_Image_Folders – script to organize test data into folders
Create_Validation_Image_Folders – script to organize validation data
MobileNetV2 - Training – main training file for the MobileNetV2 model
ResNet50 - Best_Model_Training_and_Saving – training file for the ResNet50 model
Training-Resnet50 – additional ResNet50 training configuration
Multiline-plots and Multiline-plots - Resnet50 – visualizations and performance graphs
Test-Images-For-Binary-Classification (MobileNetV2 / ResNet50) – example test results for both models
create_images.ipynb – Jupyter notebook for generating spiral images from coordinate data
LICENSE – project license information
README.md – documentation file (this file)


Contact

Author: Ishan Dave
Email: idave0425@gmail.com
Affiliation: University of California, Berkeley
ORCID: 0009-0009-4266-5610


